\chapter{Systemidentifikation im Frequenzbereich}

Neben der Systemidentifikation im Zeitbereich ist es möglich die Parameterschätzung auch im Frequenzbereich durchzuführen. 
Die Analyse im Frequenzbereich bringt einige Vorteile mit sich, die im weiteren Verlauf dieser Dokumentation genauer 
beleuchtet werden. Die Grundlage der Frequenzanalyse ist die Fouriertransformation der gemessenen Daten vom Zeitbereich in 
den Frequenzbereich. Ausgehend von den transformierten Messwerten wird im Folgenden genauer auf die Idee der 
\textit{Output Error}-Methode und auf den Algorithmus zur Lösung des Schätzproblems eingegangen. Zum Schluss werden die 
Ergebnisse 
bewertet und der Blick auf mögliche Verbesserungen und andere Methoden gerichtet.


\section{Fouriertransformation}  

\begin{align}
	j\omega_{k}\mathbf{\tilde{x}}(k)  &= \mathbf{A\tilde{x}}(k) + \mathbf{B\tilde{u}}(k) \nonumber \\
 	\mathbf{\tilde{y}}(k)             &= \mathbf{C\tilde{x}}(k) + \mathbf{D\tilde{u}}(k) = \mathbf{G}(k,\mathbf{\theta})\mathbf{\tilde{u}}(k) \nonumber \\
 	\text{mit }\mathbf{G}(k,\mathbf{\theta}) &= \mathbf{C}(j\omega\mathbf{I}-\mathbf{A})^{-1}\mathbf{B}+\mathbf{D}
	\label{eq:ZRD_Frequenzbereich}
\end{align}

\missingfigure{Bild von Fourier-Trafo}


\section{\textit{Output Error}-Methode}

Die Idee der \textit{Output Error}-Methode (OEM) liegt in der Art der Fehlerbetrachtung. Es wird dabei der Fehler, der durch 
die 
mathematische Modellbildung entsteht, vernachlässigt. Das dynamische System wird als deterministisch angenommen. 
Unsicherheiten entstehen nur durch fehlerhafte und verrauschte Messungen. Ausgangspunkt der OEM ist das transformierte 
Zustandsraummodell (\ref{eq:ZRD_Frequenzbereich}). Im vorliegenden Fall entspricht der Ausgangsvektor $\tilde{y}$ dem 
Zustandsvektor $\tilde{x}$. Die Matrizen $\mathbf{C}$ und $\mathbf{D}$ nehmen also folgende Gestalt an:

\begin{align}
	\mathbf{C} &= \mathbf{I} \nonumber \\
 	\mathbf{D} &= \mathbf{0}          
	\label{eq:CD}
\end{align}

Da der Zustandsvektor gleichzeitig der gemessene Zustand ist, kann der \textit{Output Error} folgendermaßen formuliert werden:

\begin{equation}
    \mathbf{\tilde{\nu}}(k,\mathbf{\theta}) = \mathbf{\tilde{z}}(k)-\mathbf{\tilde{y}}(k,\mathbf{\theta}) = \mathbf{\tilde{z}}(k)-\mathbf{G}(k,\mathbf{\theta})\mathbf{\tilde{u}}(k)  
	\label{eq:Output_Error}
\end{equation}

$\mathbf{\tilde{z}}$ entspricht dabei dem gemessenen Zustand, der durch\todo{durch = zusammen mit dem} Messrauschen aus dem 
übertragenen Zustand 
$\mathbf{\tilde{y}}$ entsteht. Der übertragene Zustand kann aus den Steuergrößen $\mathbf{\tilde{u}}$ durch Multiplikation 
mit der Übertragungsmatrix $\mathbf{G}(\mathbf{\theta)}$ berechnet werden. Die Übertagungsmatrix ist, wie in 
\cref{eq:ZRD_Frequenzbereich} gezeigt, abhängig vom zugrunde liegenden Modell und von den zu schätzenden Parametern 
$\mathbf{\theta}$. Diese sind die Einträge der Matrizen des Zustandsraummodells. Das Ziel der Methode ist nun den Ausgangsvektor, der aus dem Modell und seinen Parametern folgt, dem gemessenen Zustand möglichst gut anzunähern. Mathematisch bedeutet das, dass das Minimum einer Kostenfunktion gefunden werden soll. Die Kostenfunktion der OEM ist nach Klein und Morelli \cite{Klein2006} die negative Log-likelihood Funktion mithilfe des Ansatzes des Ausgangsfehlers (Gl. \ref{eq:Output_Error}):

 \begin{equation}
    J(\mathbf{\theta})=N \sum\limits_{k=0}^{N-1}\mathbf{\tilde{\nu}}^H(k,\mathbf{\theta})\mathbf{S_{\nu\nu}^{-1}}\mathbf{\tilde{\nu}}(k,\mathbf{\theta})+Nln|\mathbf{S_{\nu\nu}}|
	\label{eq:Kostenfunktion}
\end{equation}  

\todo{Svv kurz in ein zwei Sätzen erklären}
Wie bereits beschrieben, geht es nun darum das Minimum dieser Kostenfunktion zu finden. Wir suchen also die Nullstelle ihrer Ableitung. Einer der wichtigsten Algorithmen zur Bestimmung von Nullstellen (nicht)-linearer Funktionen sowohl bei Eingrößenproblemen, als auch bei Mehrgrößenproblemen ist der iterative Newton Raphson Algorithmus. Dabei wird die Nullstelle mithilfe der Richtung der Tangentensteigung iterativ angenähert. Das Problem lässt sich folgendermaßen beschreiben: \noindent \\

\noindent \tab Gesucht ist die Nullstelle s einer Funktion $f(x)$ mit $f(s)=0$ für $x=s$ \\
\tab $\overline{x}$ sei ein Punkt in der Umgebung der Nullstelle.\\

Stellt man nun eine Taylor-Reihe um $\overline{x}$ auf und vernachlässigt die Terme höherer Ordnung erhält man die Iterationsvorschrift des Newton-Raphson-Verfahrens:

 \begin{equation}
	x_{i+1} = x_{i} - \frac{f(x_{i})}{f'(x_{i})} \text{ für }i=0,1,2...
	\label{eq:Newton_Raphson}
\end{equation}  

Diese Vorschrift lässt sich umformulieren für einen mehrdimensionalen Funktionsvektor $\mathbf{F}$:

 \begin{equation}
	\underbrace{\begin{pmatrix}
	\frac{\delta f_{1}}{\delta x_{1}} & \frac{\delta f_{1}}{\delta x_{2}} & ... & \frac{\delta f_{1}}    		{\delta x_{n}}\\
	\frac{\delta f_{2}}{\delta x_{1}} & \frac{\delta f_{2}}{\delta x_{2}} & ... & \frac{\delta f_{2}}			{\delta x_{n}}\\
	... & ... & ... & ...\\
	\frac{\delta f_{n}}{\delta x_{1}} & \frac{\delta f_{n}}{\delta x_{2}} & ... & \frac{\delta f_{n}}			{\delta x_{n}}\\
	\end{pmatrix}^{i}}_{\substack{\mathbf{J^{i}}}}
	\underbrace{\begin{pmatrix}
	\Delta x_{1}\\
	\Delta x_{2}\\
	...\\
	\Delta x_{n}\\
	\end{pmatrix}^{i+1}}_{\substack{\Delta \mathbf{X^{i+1}}}} = -
	\underbrace{\begin{pmatrix}
	f_{1}\\
	f_{2}\\
	...\\
	f_{n}\\
	\end{pmatrix}^{i}}_{\substack{\mathbf{F^{i}}}}
	\label{eq:Newton_Raphson_MIMO}
\end{equation} 

Da wir das Miminum der Kostenfunktion suchen ist unser Funktionsvektor die Ableitung der Kostenfunktion nach den einzelnen zu schätzenden Parametern. 

\begin{equation}
	{F} = \frac{\delta J}{\delta \mathbf{\theta}}
	\label{eq:Newton_Raphson_1}
\end{equation}

Wir suchen die Nullstelle dieser Funktion. Mithilfe von Gleichung \ref{eq:Newton_Raphson_MIMO} können wir die Vorschrift für unser Problem umschreiben:

\begin{align}
	\Delta \mathbf{\theta}^{i+1} &= -\left(\left[  \frac{\delta^{2}J}{\delta \mathbf{\theta} \delta \mathbf{\theta^T}}\right]^{-1} \right)^{i} \cdot \left(\frac{\delta J}{\delta \mathbf{\theta}}\right)^{i} \nonumber \\
	\theta^{i+1} &= \theta^{i} + \Delta\theta^{i+1}
	\label{eq:Newton_Raphson_2}
\end{align}

In jedem Iterationsschritt muss also ein lineares Gleichungssystem gelöst werden. Das größte Problem bei der Implementierung des Algoritmus ist die Berechnung der Ableitungen und der Hesse-Matrix in jedem Iterationsschritt. Diese können bei vielen zu schätzenden Parametern schnell sehr kompliziert werden. Da die Kostenfunktion als Summe über alle Frequenzen berechnet wird (siehe Gleichung \ref{eq:Kostenfunktion}), gilt dies auch für die Ableitungen. Dadurch wird zusätzlich Rechenzeit beansprucht.  

\section{Ergebnisse}